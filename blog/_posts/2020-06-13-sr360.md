---
title: SR360：基于超分辨率提升360视频的传输
# image: /assets/img/blog/...
description: >
  这是一篇NASSDAV 2020的文章(SR360: Boosting 360-Degree Video Streaming with Super-Resolution)，主要是利用超分辨率(super-resolution)的技术来提升360视频的传输
# cofigure what you want to add in the end of the post, [about, newsletter, related, random, license]
addons: [license]
# the tag of post.
tags: [PAPER]
---

由于360视频能够为用户提供身临其境的观看体验，因此越来越受欢迎。在网络带宽有限的情况下，常常基于用户的**Field of View**（FoV）来优化360视频的传输。但是，由于用户行为多样且网络条件时间上变化的不确定性，很难进行准确的FoV预测。因此在本文中，我们基于超分辨率（SR）技术重新设计了360视频的传输系统。我们提出的SR360框架的基本思想是利用用户设备上的计算资源来减少网络的压力。在SR360中，可以使用客户端的SR技术将低分辨率的视频块提升为高分辨率的视频块。我们采用深度强化学习（DRL）的理论制定一套决策，包括用户FoV预测，比特率分配和SR增强。我们将SR360与其他最新方法的性能进行了比较，结果表明，在不同的QoE指标下，SR360的性能平均比其他方法至少好30％。

# 主要内容
根据[Cisco的一份报告](http://www.cisco.com/c/en/us/solutions/collateral/service-provider/visual-networking-index-vni/complete-white-paper-c11-481360.htm)，沉浸式视频应用会越来越火，尤其是360视频。但是这类视频所需要的传输带宽又很大，看作者的描述:

> To achieve a fairly immersive experience, the video resolution of 360-degree video needs to be at least 8K, which corresponds to a network throughput of 400 Mbps and above.

过去的方法基本上是基于FoV的预测来进行的，但是预测的精度不高。作者总结了360视频传输的一些挑战：
* **insufficient bandwidth**  带宽的不足以及不稳定影响到用户观看体验
* **erroneous FoV prediction**  用户行为的多变性以及视频类型的影响，导致FoV预测不准确也影响到用户的观看体验
* **coupling influential factors**  有很多影响码率决策的因素，包括网络的变化，目光的转动等
* **multi-dimensional QoE**  要考虑多维度的QoE指标，包括视频质量，缓冲时间，播放的平滑度等

本文的主要内容就是利用超分辨率(SR)对360视频中的tiles进行重建，并且使用深度强化学习(DRL)的方法来**预测FoV**，**为每一个tile决策码率**并且**决策视频是否应该进行SR操作**。

# SR360系统框架
SR360服务端负责将360视频切片(segments)切块(tiles)，视频编码(多码率)，视频存储以及处理请求。<br>
客户端负责下载视频，预测Fov和决策码率，视频解码以及超分重建等。系统架构如图所示：<br>
![]({{site.data.strings.blog_url}}sr360-arch.png)

## content-aware super-resolution
设计一个能够重建各种类型视频的网络是不可能的，所以本文为每一个视频都训练一个模型...
> To address the above challenge, we consider a content-aware SR model in which an independent SR model is built for each video.

考虑到对整帧图形进行重建，计算量太大，实时性不高(作者做了一个实验)，决定对tile进行重建，而且FoV内的tile重建优先级最高。另外，作者考虑的是一开始就传一个完整的DNN，和[NAS](https://www.usenix.org/conference/osdi18/presentation/yeo)不一样。

## problem formulation
其实就是最大化QoE，QoE定义如下：<br>
$$QoE_{k} = \alpha QoE_{1 , k} - \beta QoE_{2 , k} - \omega QoE_{3 , k} $$  <br>
其中,<br>
* $$QoE_{1 , k}$$为平均视频质量，主要是计算用户视角内的平均视频块质量，使用[SSIM](https://ieeexplore.ieee.org/abstract/document/1284395)评价图像质量
* $$QoE_{2 , k}$$为卡顿时间，就普通的计算，下载时间加重建时间减去缓冲区长度
* $$QoE_{3 , k}$$为视频平滑度，定义为帧间(帧内tiles求和)的质量差异

## DRL算法
决策的东西就是码率，viewport以及需要重建的tiles。其中码率是指viewport内的tiles，非viewport码率设为最低；重建也只针对viewport内的tiles。
* **states**  包括平均码率，缓冲区长度，网络吞吐量，块的下载时间，viewport内各码率版本文件大小，过去viewport中tiles的序列号以及剩余的chunk的个数。
* **actioins**  viewport的位置，viewport内tiles的码率版本以及是否重建viewport内的tiles。
* **rewards**  $$\tau_{k} = \alpha QoE_{1 , k} - \beta QoE_{2 , k} - \omega QoE_{3 , k} - \mu A_{k}$$,，其中$$A_{k}$$为视口预测的惩罚。

# 实验
* **videos and head movement tarces**  [traces](https://dl.acm.org/doi/abs/10.1145/3083187.3083215), [codec](https://github.com/ultravideo/kvazaar)
* **bandwidth traces**  [traces](https://ieeexplore.ieee.org/abstract/document/7546928)
## 对比实验
[baseline](https://dl.acm.org/doi/abs/10.1145/1943552.1943572), [H2P](https://dl.acm.org/doi/abs/10.1145/3123266.3123453), [Plato](https://ieeexplore.ieee.org/abstract/document/8638092/), [DRL360](https://ieeexplore.ieee.org/abstract/document/8737361/).

# 总结
本文主要就是应用DRL对码率，viewport以及重建tiles进行决策，思路很简单。不过好像没有实现原型系统。。。<br>


<br>
感兴趣的可以[阅读原文](https://dl.acm.org/doi/abs/10.1145/3386290.3396929)